{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961d4fba",
   "metadata": {},
   "source": [
    "# 4-4: Sparse Categorical Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73116893-f8ba-4fb4-9d82-c92d77a2c31d",
   "metadata": {},
   "source": [
    "### Code.4-4-1: SCCE Calcrulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2758b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCCE(Tensorflow): 1.8018494\n",
      "SCCE(Menual): 1.8018494\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "batch_size, n_class = 16,5\n",
    "\n",
    "predictions = tf.random.uniform(shape=(batch_size,n_class), #마지막 layer는 각데이터가 class개수만큼 나와야하기때문에, (batch_size,n_class)으로 shape가 형성되어야한다.\n",
    "                               minval=0,maxval=1,\n",
    "                               dtype=tf.float32)\n",
    "pred_sum = tf.reshape(tf.reduce_sum(predictions,axis=1),(-1,1)) #한 layers내에 있는 각 neurons 결괏값들의 합.\n",
    "#print(predictions.shape,pred_sum.shape) 결과를 보면, 5개의 n_class가 pred_sum을 통해 1개의 class로 변했음을 알 수 있다.\n",
    "predictions = predictions/pred_sum #항상 한 layer내에 있는 각 neurons 결괏값들의 합은 1이돼야하기 때문에, pred_sum으로 나워준다. 이렇게 되면, predictions의 합은 무조건 1이 되기때문 ㅎ\n",
    "\n",
    "labels = tf.random.uniform(shape=(batch_size,),\n",
    "                          minval=0,maxval=n_class,\n",
    "                          dtype=tf.int32)   #labels는 0부터 4까지 정수로 구성된 (batch_size,)의 형태로 만들어준다.\n",
    "\n",
    "#tenserflow내에 있는 패키지 활용.\n",
    "loss_object = SparseCategoricalCrossentropy()\n",
    "loss = loss_object(labels, predictions)\n",
    "print(\"SCCE(Tensorflow):\",loss.numpy())\n",
    "\n",
    "#실제 공식을 활용하여 loss값구하기.\n",
    "ce = 0\n",
    "for label, prediction in zip(labels,predictions):\n",
    "    ce += -tf.math.log(prediction[label])\n",
    "ce /=batch_size\n",
    "print(\"SCCE(Menual):\",ce.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01c38b-3570-446a-ae75-89c759c17a59",
   "metadata": {},
   "source": [
    "### Code.4-4-2: SCCE with Model/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43a1b33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.81967\n",
      "10.124693\n",
      "10.492644\n",
      "10.605381\n",
      "10.190081\n",
      "9.7218685\n",
      "3.0947025\n",
      "0.41211507\n",
      "0.44514546\n",
      "0.3981114\n",
      "0.4485567\n",
      "0.43118683\n",
      "1.579084\n",
      "3.4739544\n",
      "3.4371014\n",
      "2.8629012\n",
      "3.7699566\n",
      "2.8660102\n",
      "4.644404\n",
      "8.471378\n",
      "8.574875\n",
      "8.4469\n",
      "8.283646\n",
      "8.400702\n",
      "8.165389\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "SCCE: tf.Tensor(8.697529, shape=(), dtype=float32)\n",
      "loss_row: 32\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "N,n_feature = 100,2\n",
    "n_class = 5\n",
    "\n",
    "X = tf.zeros(shape=(0,n_feature))\n",
    "Y = tf.zeros(shape = (0,1),dtype=tf.int32)\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "for class_idx in range(n_class):\n",
    "    center = tf.random.uniform(minval=-15,maxval=15,shape=(2,))\n",
    "    \n",
    "    x1 = center[0] + tf.random.normal(shape=(N,1))\n",
    "    x2 = center[1] + tf.random.normal(shape=(N,1))\n",
    "    \n",
    "    x = tf.concat((x1,x2),axis=1)\n",
    "    y = (class_idx+1) * tf.ones(shape=(N,1),dtype=tf.int32)\n",
    "    \n",
    "    X = tf.concat((X,x),axis=0)\n",
    "    Y = tf.concat((Y,y),axis=0)\n",
    "#여기까지는 dataset을 구성한 것.\n",
    "\n",
    "batch_size = 16\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "model = Dense(units = n_class, activation = \"softmax\") #multi-class이기 때문에, softmax를 activation으로 사용한다. neurons의 개수는 n_class.\n",
    "loss_object = SparseCategoricalCrossentropy()\n",
    "\n",
    "loss_sum = 0\n",
    "loss_row = 0\n",
    "for x, y in dataset:\n",
    "    predictions = model(x)\n",
    "    loss = loss_object(y,predictions)\n",
    "    print(loss.numpy())\n",
    "    loss_row += 1\n",
    "    loss_sum += loss\n",
    "print(\"SCCE:\",loss_sum/batch_size)\n",
    "print(\"loss_row:\",loss_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a90af",
   "metadata": {},
   "source": [
    "# 4-5: Categorical Cross Entropy\n",
    "one-hot encoding 된 상태에서 loss값을 계산해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb42db-2f7a-4ba3-a401-0c16bf0c66d7",
   "metadata": {},
   "source": [
    "### Code 4-5-1: CCE Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "397e9eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCE(Tensorflow): 1.7213991\n",
      "CCE(Menual): 1.7213991\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "batch_size, n_class = 16,5\n",
    "\n",
    "predictions = tf.random.uniform(shape=(batch_size,n_class),\n",
    "                               minval=0,maxval=1,\n",
    "                               dtype=tf.float32)\n",
    "pred_sum = tf.reshape(tf.reduce_sum(predictions,axis=1),(-1,1))\n",
    "predictions = predictions/pred_sum\n",
    "\n",
    "labels = tf.random.uniform(shape=(batch_size,),\n",
    "                          minval=0,maxval=n_class,\n",
    "                          dtype=tf.int32)\n",
    "\n",
    "labels = tf.one_hot(labels, n_class) #one-hot vector로 변형\n",
    "\n",
    "loss_object = CategoricalCrossentropy() #CategoricalCrossentropy는 Y label이 one-hot encoding이 되어 있을때 하는것.\n",
    "loss = loss_object(labels, predictions)\n",
    "\n",
    "print(\"CCE(Tensorflow):\",loss.numpy())\n",
    "\n",
    "cce_man = tf.reduce_mean(tf.reduce_sum(-labels *tf.math.log(predictions),axis=1))\n",
    "\n",
    "print(\"CCE(Menual):\",cce_man.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831879d4-ae93-4ad2-8a13-997cb97ba8d7",
   "metadata": {},
   "source": [
    "### Code.4-5-2: CCE with Model/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ebf1c8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.31924\n",
      "9.251816\n",
      "17.666653\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "N,n_feature = 8,2\n",
    "n_class = 5\n",
    "\n",
    "X = tf.zeros(shape=(0,n_feature))\n",
    "Y = tf.zeros(shape = (0,),dtype=tf.int32)\n",
    "\n",
    "tf.random.set_seed(1) \n",
    "\n",
    "for class_idx in range(n_class):\n",
    "    center = tf.random.uniform(minval=-15,maxval=15,shape=(2,))\n",
    " \n",
    "    x1 = center[0] + tf.random.normal(shape=(N,1))\n",
    "    x2 = center[1] + tf.random.normal(shape=(N,1)) \n",
    "    \n",
    "    x = tf.concat((x1,x2),axis=1)\n",
    "    y = class_idx * tf.ones(shape=(N,),dtype=tf.int32)\n",
    "    \n",
    "    X = tf.concat((X,x),axis=0)\n",
    "    Y = tf.concat((Y,y),axis=0)\n",
    "    \n",
    "Y = tf.one_hot(Y,depth=n_class, dtype=tf.int32) #one-hot encoding을 실행한 것.\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "model = Dense(units = n_class, activation = \"softmax\") #multi-class이기 때문에, softmax를 activation으로 사용한다. neurons의 개수는 n_class.\n",
    "loss_object = CategoricalCrossentropy()\n",
    "\n",
    "for x, y in dataset:\n",
    "    predictions = model(x)\n",
    "    loss = loss_object(y,predictions)\n",
    "    print(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c821e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
